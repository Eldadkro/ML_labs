{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regular expressins packge\n",
    "# import numbers package\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def readFile(fileName):\n",
    "    file = open(fileName,'r',encoding=\"cp437\")\n",
    "    fileStr = \"\"\n",
    "    for line in file:\n",
    "        fileStr += line\n",
    "    return fileStr\n",
    "        \n",
    "# Remove extra spaces\n",
    "# Remove non-letter chars    \n",
    "# Change to lower \n",
    "def preProcess(fileStr):\n",
    "    fileStr = re.sub(\" +\",\" \", fileStr)\n",
    "    fileStr = re.sub(\"[^a-zA-Z ]\",\"\", fileStr)\n",
    "    fileStr = fileStr.lower()\n",
    "    return fileStr\n",
    "\n",
    "if __name__ == \"__main__\":          \n",
    "    rows = 5\n",
    "    fileContent = [\"\"]*rows\n",
    "\n",
    "    #read  and preprocess files \n",
    "    fileContent[0] = preProcess(readFile('DB.txt'))\n",
    "    fileContent[1] = preProcess(readFile('HP_small.txt'))\n",
    "    fileContent2 = preProcess(readFile('Tolkien.txt'))\n",
    "    numParts = 3\n",
    "    # split the third file to parts\n",
    "    partLength = int(len(fileContent2)/numParts) \n",
    "    fileContent[2]  = fileContent2[0:partLength]\n",
    "    fileContent[3]  = fileContent2[partLength:partLength*2]\n",
    "    fileContent[4]  = fileContent2[partLength*2:partLength*3]\n",
    "    #___________________________________ \n",
    "    # construct DICTIONARY concat files contents\n",
    "    numFiles = rows\n",
    "    allFilesStr = \"\"\n",
    "    for i in range(numFiles):\n",
    "        allFilesStr += fileContent[i]\n",
    "\n",
    "    # generate a set of all words in files \n",
    "    wordsSet =  set(allFilesStr.split())\n",
    "\n",
    "    # Read stop words file - words that can be removed\n",
    "    stopWordsSet = set(readFile('stopwords_en.txt').split())\n",
    "    # Remove the stop words from the word list\n",
    "    dictionary = wordsSet.difference(stopWordsSet)\n",
    "    #_______________________________________\n",
    "    # count the number of dictionary words in files\n",
    "    wordFrequency = np.empty((rows,len(dictionary)),dtype=np.int64)\n",
    "    for i in range(rows):\n",
    "        for j,word in enumerate(dictionary):\n",
    "            wordFrequency[i,j] = len(re.findall(word,fileContent[i]))\n",
    "\n",
    "    # find the distance matrix between the text files\n",
    "    dist = np.empty((rows,rows))\n",
    "    for i in range(rows): \n",
    "        for j in range(rows):\n",
    "            # calculate the distance between the frequency vectors\n",
    "            dist[i,j] = np.linalg.norm(wordFrequency[i,:]-wordFrequency[j,:])\n",
    "\n",
    "    print(\"dist=\\n\",dist)\n",
    "\n",
    "    # find the sum of the frequency colomns and select colomns having sum > 20\n",
    "    minSum = 20\n",
    "    sumArray =  wordFrequency.sum(axis=0)\n",
    "    indexArray = np.where(sumArray > minSum)\n",
    "\n",
    "    wordFrequency2 = np.zeros((row,len(indexArray)),dtype = np.int64)\n",
    "\n",
    "    for index,i in enumerate(indexArray):\n",
    "        wordFrequency2\n",
    "\n",
    "\n",
    "a = np.empty((2,2))\n",
    "a[:,0] = np.zeros((2,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}